<!DOCTYPE HTML>
<!--
	Forty by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
	<style>

	</style>
</head>

<head>
	<title>Experience - Vijay Jawali</title>
	<link rel="icon" href="images/icon.jpg" type="image/jpg">
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="assets/css/main.css" />
	<noscript>
		<link rel="stylesheet" href="assets/css/noscript.css" />
	</noscript>
</head>

<body class="is-preload">

	<!-- Wrapper -->
	<div id="wrapper">

		<!-- Header -->
		<!-- Note: The "styleN" class below should match that of the banner element. -->
		<header id="header" class="alt style2">
			<a href="index.html" class="logo"><strong>VIJAY</strong> <span>HOME</span></a>
			<nav>
				<a href="https://linktr.ee/vijayjawali" target="_blank">CONTACT</a>
				<a href="#menu">Menu</a>
			</nav>
		</header>

		<!-- Menu -->
		<nav id="menu">
			<ul class="links">
				<li><a href="index.html">Home</a></li>
				<li><a href="projects.html" class="link">Projects</a></li>
				<li><a href="certifications.html" class="link">Certifications</a></li>
				<li><a href="skills.html" class="link">Skills</a></li>
				<li><a href="education.html" class="link">Education</a></li>
				<li><a href="articles.html" class="link">Articles</a></li>
			</ul>
		</nav>

		<!-- Banner -->
		<!-- Note: The "styleN" class below should match that of the header element. -->
		<section id="banner" class="style2">
			<div class="inner">
				<span class="image">
					<img src="images/pic07.jpg" alt="" />
				</span>
				<header class="major">
					<h1>Work Experience</h1>
				</header>
				<div class="content">
					<blockquote>
						"Experience is the teacher of all things." - Julius Caesar
					</blockquote>

				</div>
			</div>
		</section>
		<br>
		<hr class="separation-line">
		<br>



		<div class="timeline">

			<a href="#walmart" class="timeline-item">
				<div class="timeline-card">
					<h3 class="timeline-date">April 2024 - present</h3>
					<div class="timeline-content">
						<h4>Walmart Global Tech</h4>
						<p>Software Engineer III</p>
					</div>
				</div>
			</a>
			<a href="#altimetrik" class="timeline-item">
				<div class="timeline-card">
					<h3 class="timeline-date">November 2023 - April 2024</h3>
					<div class="timeline-content">
						<h4>Intuit (payroll Altimetrik)</h4>
						<p>Senior Engineer</p>
					</div>
				</div>
			</a>
			<a href="#socgen" class="timeline-item">
				<div class="timeline-card">
					<h3 class="timeline-date">November 2021 - September 2022</h3>
					<div class="timeline-content">
						<h4>Societe Generale</h4>
						<p>Specialist Software Engineer</p>
					</div>
				</div>
			</a>
			<a href="#mindtreeSE" class="timeline-item">
				<div class="timeline-card">
					<h3 class="timeline-date">June 2020 - November 2021</h3>
					<div class="timeline-content">
						<h4>Mindtree</h4>
						<p>Senior Engineer</p>
					</div>
				</div>
			</a>
			<a href="#mindtreeE" class="timeline-item">
				<div class="timeline-card">
					<h3 class="timeline-date">January 2019- June 2020</h3>
					<div class="timeline-content">
						<h4>Mindtree</h4>
						<p>Engineer</p>
					</div>
				</div>
			</a>
			<a href="#mindtreeTE" class="timeline-item">
				<div class="timeline-card">
					<h3 class="timeline-date">October 2018 - December 2018</h3>
					<div class="timeline-content">
						<h4>Mindtree</h4>
						<p>Trainee Software Engineer</p>
					</div>
				</div>
			</a>
		</div>

		<br>
		<hr class="separation-line">
		<br>


		<!-- Main -->
		<div id="main">

			<section id="walmart">
				<div class="inner">
					<header class="major">
						<h2>Walmart Global Tech</h2>
					</header>
					<div class="container">
						<div class="content">
							<p>Software Engineer III</p>
						</div>
						<div class="content" style="text-align: center;">
							<p>April 2024 - present</p>
						</div>
						<header class="major">
							<h4>Technologies:</h4>
						</header>
						<button class="skill">Scala</button>
						<button class="skill">Apache Spark</button>
						<button class="skill">Google BigQuery</button>
						<button class="skill">Apache Airflow</button>
						<button class="skill">Google Data Store</button>
						<button class="skill">Jenkins</button>
						<button class="skill">Confluent Kafka</button>

						<br>
						<br>

						<button class="skill">Apache Superset</button>
						<button class="skill">WCNP (Walmart Cloud Native Platform)</button>
						<button class="skill">Kubernates</button>
						<button class="skill">PostgreSQL</button>
						<button class="skill">MySQL</button>
						<hr>
						<header class="major">
							<h4>Skills:</h4>
						</header>

						<button class="skill">Big Data</button>
						<button class="skill">Data Analytics</button>
						<button class="skill">NoSQL</button>
						<button class="skill">Database Management</button>
						<button class="skill">Pipeline Orchestration</button>
						<button class="skill">Large-scale data processing</button>

						<br>
						<br>
						<button class="skill">Performance tuning</button>
						<button class="skill">Security and Compliance</button>
						<button class="skill">Data Warehousing</button>
						<button class="skill">Data validation</button>
						<button class="skill">System design</button>

						<button class="skill">Distributed computing</button>
						<hr>
						<header class="major">
							<h4>Achievements:</h4>
						</header>

						&star;
						Led enterprise-wide migration of Apache Spark applications from version 2.x to 3.x, ensuring
						seamless transition while improving performance by 25% and maintaining functionality with
						reduced cloud computing costs.
						<br>
						&star;
						Automated financial reconciliation system integrating data sources to validate $1.5B+ in daily
						transactions, reducing reconciliation time from 7 to 2 days and eliminating manual verification
						efforts.
						<br>
						&star;
						Architected and implemented data archival solution between GCP Cloud Storage and PostgreSQL,
						automating archival workflows enabling compliance with data retention policies, resulting in a
						30% reduction in database storage costs.
						<br>
						&star;
						Performed complex database migration projects, successfully transferring 25 GB of data from
						MySQL to PostgreSQL while ensuring zero data loss and minimal downtime.
						<br>
						&star;
						Achieved increased operational efficiency by employing Bash and Python scripting languages to
						automate repetitive tasks, streamline job scheduling processes and manage clusters on GCP and
						WCNP (Walmart Cloud native Platform).

						<hr>
						<header class="major">
							<h4>Responsibilities:</h4>
						</header>


						<ul>
							<li>Data Pipeline Development and Maintenance
								<ul>
									<li>Design, develop, and maintain scalable data pipelines for financial data
										processing</li>
									<li>Implement business logic for data transformation and enrichment</li>
									<li>Ensure data quality and accuracy through validation checks</li>
									<li>Monitor pipeline performance and SLAs</li>
									<li>Troubleshoot and resolve data processing issues in production environments</li>
								</ul>
							</li>
							<li>Financial Data Integration and Reconciliation
								<ul>
									<li>Coordinate with multiple teams to understand source data formats and business
										requirements</li>
									<li>Implement data integration patterns for various vendor sources</li>
									<li>Develop automated reconciliation processes for financial transactions</li>
									<li>Maintain data lineage and documentation</li>
									<li>Ensure compliance with financial reporting standards</li>
								</ul>
							</li>
							<li>Infrastructure and Platform Management
								<ul>
									<li>Manage and optimize GCP resources for cost and performance</li>
									<li>Implement and maintain database systems (PostgreSQL, MySQL)</li>
									<li>Configure and optimize Apache Spark clusters</li>
									<li>Set up and maintain workflow orchestration tools (Airflow, Jenkins)</li>
									<li>Implement security best practices and vulnerability fixes</li>
								</ul>
							</li>
							<li>Performance Optimization and Testing
								<ul>
									<li>Profile and optimize Spark jobs for better performance</li>
									<li>Develop and maintain automated testing frameworks</li>
									<li>Conduct performance testing and benchmarking</li>
									<li>Implement monitoring and alerting systems</li>
									<li>Create and maintain test data sets and testing environments</li>
								</ul>
							</li>
							<li>Technical Leadership and Collaboration
								<ul>
									<li>Provide technical guidance and mentorship to team members</li>
									<li>Collaborate with business stakeholders to understand requirements</li>
									<li>Work with SAP team for financial reporting integration</li>
									<li>Participate in architecture discussions and technical design reviews</li>
									<li>Document technical solutions and maintain knowledge base</li>
								</ul>
							</li>
						</ul>
					</div>
				</div>
			</section>


			<section id="altimetrik">
				<div class="inner">
					<header class="major">
						<h2>Intuit (payroll Altimetrik)</h2>
					</header>
					<div class="container">
						<div class="content">
							<p>Senior Engineer</p>
						</div>
						<div class="content" style="text-align: center;">
							<p>November 2023 - April 2024</p>
						</div>
						<header class="major">
							<h4>Technologies:</h4>
						</header>
						<button class="skill">Python</button>
						<button class="skill">Pandas</button>
						<button class="skill">OpenAI</button>
						<button class="skill">Plotly Dash</button>
						<button class="skill">ngrok</button>
						<button class="skill">Cloud Computing</button>
						<button class="skill">Cloud Deployment</button>
						<br>
						<br>

						<button class="skill">Apache Spark</button>
						<button class="skill">Hive</button>
						<button class="skill">Apache Oozie</button>
						<button class="skill">Databricks</button>
						<button class="skill">AWS S3</button>
						<button class="skill">SparkSQL</button>
						<button class="skill">AWS Glue</button>
						<button class="skill">AWS EMR</button>
						<button class="skill">Informatica</button>
						<button class="skill">QuickBase</button>
						<hr>
						<header class="major">
							<h4>Skills:</h4>
						</header>

						<button class="skill">Large Language Models</button>
						<button class="skill">Natural Language Processing</button>
						<button class="skill">Generative AI</button>
						<button class="skill">Fine-tuning</button>
						<button class="skill">Log Anomaly Detection</button>
						<button class="skill">Root Cause Analysis</button>
						<button class="skill">Data Visualization</button>
						<button class="skill">Data Management</button>
						<button class="skill">ETL</button>
						<button class="skill">Data Wrangling</button>
						<button class="skill">Model Evaluatiion</button>
						<br>
						<br>
						<button class="skill">Data Warehousing</button>
						<button class="skill">Business Insights</button>
						<button class="skill">Data Management</button>
						<button class="skill">Databases</button>
						<button class="skill">Extract, Transform, Load</button>
						<button class="skill">Data Engineering</button>
						<button class="skill">Big Data</button>
						<button class="skill">SQL</button>
						<button class="skill">NoSQL</button>
						<button class="skill">Data Analytics</button>

						<hr>
						<header class="major">
							<h4>Achievements:</h4>
						</header>

						&star; Received “Team” Award from Altimetrik, for presenting POC on Gen AI.
						<br>
						&star; Developed an advanced application for infrastructure monitoring using cutting-edge AI and
						machine learning techniques, addressing critical challenges in system reliability, error
						detection, and debugging.
						<br>
						&star; Integrated Natural Language Processing (NLP) techniques to extract log patterns, compare
						against known error signatures, and interpret new logs in the context of historical failure
						models.
						<br>
						&star; Implemented a log anomaly detection model leveraging the GPT-3.5 Turbo from OpenAI,
						fine-tuned on a custom dataset of over 2000 real-world Spark application logs.
						<br>
						&star; Designed an intuitive web interface using Plotly Dash and Dash Components, enabling users
						to input raw unstructured logs and receive real-time anomaly detection, root cause analysis, and
						suggested fixes.
						<br>
						<hr>
						<header class="major">
							<h4>Responsibilities:</h4>
						</header>

						<ul>
							<li>Converted complex Informatica workflows to Apache Spark applications, enabling
								distributed computing and enhancing data processing capabilities for large-scale
								financial and supply chain data workloads.
							</li>
							<li>Orchestrated data pipelines to load data from QuickBase to AWS S3, processed data using
								Apache Spark applications on AWS EMR, and loaded the processed data back to QuickBase,
								streamlining data integration between different systems.
							</li>
							<li>Leveraged Hive databases to load and manage finance data on AWS S3, maintaining data
								integrity, accessibility, and compliance with financial reporting standards.
							</li>
							<li>Conducted comprehensive like-to-like testing and validation, comparing traditional and
								cloud-based systems to ensure accurate data migration, seamless integration, and
								adherence to data quality standards.
							</li>
						</ul>
					</div>
				</div>
			</section>

			<hr class="separation-line">

			<!-- One -->
			<section id="socgen">
				<div class="inner">
					<header class="major">
						<h2>Societe Generale</h2>
					</header>
					<div class="container">
						<div class="content">
							<p>Specialist Software Engineer</p>
						</div>
						<div class="content" style="text-align: center;">
							<p>November 2021 - September 2022</p>
						</div>
						<header class="major">
							<h4>Technologies:</h4>
						</header>
						<button class="skill">Apache Spark</button>
						<button class="skill">Scala</button>
						<button class="skill">Hadoop</button>
						<button class="skill">Hive</button>
						<button class="skill">Apache Oozie</button>
						<button class="skill">PostgreSQL</button>
						<button class="skill">Presto</button>
						<button class="skill">SparkSQL</button>
						<button class="skill">Jenkins</button>
						<button class="skill">Jira</button>
						<hr>
						<header class="major">
							<h4>Skills:</h4>
						</header>
						<button class="skill">Unstructured Data</button>
						<button class="skill">Data Warehousing</button>
						<button class="skill">Data Visualization</button>
						<button class="skill">Business Insights</button>
						<button class="skill">MapReduce</button>
						<button class="skill">Data Management</button>
						<button class="skill">Databases</button>
						<button class="skill">Extract, Transform, Load</button>
						<button class="skill">Data Engineering</button>
						<button class="skill">Big Data</button>
						<button class="skill">SQL</button>
						<button class="skill">NoSQL</button>
						<button class="skill">Data Analytics</button>
						<hr>
						<header class="major">
							<h4>Achievements:</h4>
						</header>

						&star; Developed fraud detection and financial data analysis applications on a private cloud
						environment, resulting in improved transaction security on SWIFT payment system.
						<br>
						&star; Upgraded banking data to ISO20022 standards in compliance with new regulations using
						Scala-based Spark application, resulting in a 40% reduction in processing time and improved
						accuracy.
						<br>
						&star; Implemented the use of Hive database for distributed data using advanced compression file
						formats, resulting in an 87% increase in storage efficiency.
						<br>
						&star; Created a suite of 55 reports within a span of two months to serve as a data source for
						PowerBI visualization, enabling valuable insights to be derived from a vast pool of data stored
						in a data lake.
						<br>
						&star; Demonstrated resiliency and structural consistency by performing disaster recovery tests
						and achieving 92% testing benchmarks on Hadoop production clusters.
						<br>
						<hr>
						<header class="major">
							<h4>Responsibilities:</h4>
						</header>

						<ul>
							<li>Worked on developing spark applications with Scala using Datasets in the domain of
								Correspondence Banking sector using private on-premise cloud infrastructure.
							</li>
							<li>Worked with Hive databases to store transformed data on external tables with partitions
								having various file formats including parquet, ORC in compressed format to save space up
								to 87%
							</li>
							<li>Used Oozie as a scheduling tool to run the spark jobs on specific intervals to automate
								report generation and eliminating regular manual intervention.
							</li>
							<li>Developed spark applications to migrate existing use cases from legacy Java applications
								to handle large datasets [Big Data] that are scalable for future use.
							</li>
							<li>Implemented the upgradation of Banking data to ISO20022 standards using spark
								applications while migrating them to Big Data environment to adhere to new banking
								regulations.
							</li>
							<li>Developed applications to generate a family of reports to be fed into custom UI/ PowerBI
								reports to get insights from the vast pool of data lake.
							</li>
							<li>Involved in performing Disaster Recovery tests on the functional module containing
								multiple spark jobs to test data replication, structural integrity, test plan creation,
								and SOP to be followed during a disaster.
							</li>
						</ul>
					</div>

					<p>During my experience at Société Générale in corresponding banking, I built applications to detect
						fraudulent transactions and money laundering activities in high-risk countries through the Swift
						payment system and generated reports flagging unusual transactions, I had a host of
						responsibilities that needed technical knowledge in the big data domain with skills in data
						cleaning, data analysis, building and deploying applications on cloud environments. As a
						Specialist Software Engineer, I analysed the data to be received in the system, automate the
						data quality check before ingestion into a data lake, and develop a spark application from the
						data received in HDFS distributed file system to design and build a functional data pipeline and
						finally present the data in the form of tables, reports, and visualisations. In addition, I have
						successfully designed and executed disaster recovery procedures for Spark applications within a
						private cloud environment, ensuring the resilience and uninterrupted operation of critical data
						systems.</p>
				</div>
			</section>

			<hr class="separation-line">

			<!-- Two -->
			<section id="mindtreeSE">
				<div class="inner">
					<header class="major">
						<h2>Mindtree</h2>
					</header>
					<div class="container">
						<div class="content">
							<p>Senior Engineer</p>
						</div>
						<div class="content" style="text-align: center;">
							<p>June 2020 - November 2021</p>
						</div>
						<header class="major">
							<h4>Technologies:</h4>
						</header>
						<button class="skill">Apache Spark</button>
						<button class="skill">Scala</button>
						<button class="skill">Amazon Web Services (AWS)</button>
						<button class="skill">Apache Kafka</button>
						<button class="skill">Apache Oozie</button>
						<button class="skill">PostgreSQL</button>
						<button class="skill">CouchDB</button>
						<button class="skill">SparkSQL</button>
						<button class="skill">Jenkins</button>
						<button class="skill">Jira</button>
						<hr>
						<header class="major">
							<h4>Skills:</h4>
						</header>
						<button class="skill">Unstructured Data</button>
						<button class="skill">Data Management</button>
						<button class="skill">Databases</button>
						<button class="skill">Extract, Transform, Load</button>
						<button class="skill">Data Engineering</button>
						<button class="skill">Big Data</button>
						<button class="skill">SQL</button>
						<button class="skill">NoSQL</button>
						<button class="skill">Data Analytics</button>
						<hr>

						<header class="major">
							<h4>Achievements:</h4>
						</header>
						&star; Received “A-Team” Award from Mindtree, six times for collaborative team spirit.<br>
						&star; Led the module migration from Mainframe to Cloud using Amazon S3, CouchDB and Postgres,
						resulting in a 20% reduction in data processing time with improved scalability.<br>
						&star; Created real-time data streaming applications using Apache Spark Streaming and Kafka that
						reduced data processing latency by 50%, enabling real-time decision-making for the business.<br>
						&star; Designed automated end-to-end data pipelines, leveraging 4 years of historical business
						data to validate data flow between components and eliminating manual intervention.<br>
						<hr>

						<header class="major">
							<h4>Responsibilities:</h4>
						</header>

						<ul>
							<li>Involved in End-to-End Data Integration from Source to Tables and UI.
							</li>
							<li>Involved in Business rule and Data Integrity analysis for data transformation.
							</li>
							<li>Experience in Data transformation using Scala, Python and SQL Scripts.
							</li>
							<li>Experience in working with PostgreSQL, Couchbase.
							</li>
							<li>Worked on handling 4+ years of Business Data to ensure the accuracy.
							</li>
							<li>Involved in developing Modules having multiple Spark jobs to integrate multiple Data
								Flows.
							</li>
							<li>Involved in continuous interaction with the Client providing updates and taking feedback
								on the Modules using Confluence for project collaboration.
							</li>
							<li>Responsible for Module Level job integration, worked with Legacy system to meet the Data
								accuracy requirements with Legacy and current (cloud) system.
							</li>
							<li>Involved in collecting Software Requirement Specifications at the Design Phase.
							</li>
							<li>Preparation of Test Scenarios based on the functionality.
							</li>
							<li>Worked on validating the Data flows between multiple spark jobs to execute End to End
								Data flow to table/UI.
							</li>
						</ul>
					</div>

					<p>My experience in Mindtree as a Senior Engineer exposed me to explore the Travel and Hospitality
						industry which provided me an opportunity to develop with semi-structured and unstructured data
						with varying file formats. This allowed me to get familiarize with different types of SQL and
						NoSQL databases. I applied my learning skills to develop spark applications in areas of
						Inventory Optimization, Demand and Supply, and Hotel Room Booking Forecasts. One of my notable
						achievements during this time was successfully transitioning the analytical system from a Legacy
						Mainframe network to a cloud-based AWS infrastructure within just three years and I was awarded
						six times by the team during this period for my contribution.</p>
				</div>
			</section>

			<hr class="separation-line">

			<!-- Three -->
			<section id="mindtreeE">
				<div class="inner">
					<header class="major">
						<h2>Mindtree</h2>
					</header>
					<div class="container">
						<div class="content">
							<p> Engineer</p>
						</div>
						<div class="content" style="text-align: center;">
							<p>January 2019 - June 2020</p>
						</div>
						<header class="major">
							<h4>Technologies:</h4>
						</header>
						<button class="skill">Apache Spark</button>
						<button class="skill">Scala</button>
						<button class="skill">Python</button>
						<button class="skill">AWS Cloud</button>
						<button class="skill">Oozie</button>
						<button class="skill">Apache Spark Streaming</button>
						<button class="skill">Amazon EC2</button>
						<button class="skill">Jira</button>
						<button class="skill">Confluence</button>
						<button class="skill">Amazon Elastic MapReduce</button>
						<button class="skill">Cassandra</button>
						<hr>
						<header class="major">
							<h4>Skills:</h4>
						</header>
						<button class="skill">Unstructured Data</button>
						<button class="skill">Data Visualization</button>
						<button class="skill">Analytical Skills</button>
						<button class="skill">Data Management</button>
						<button class="skill">ETL</button>
						<button class="skill">Data Engineering</button>

						<button class="skill">Couchbase</button>
						<button class="skill">PySpark</button>
						<button class="skill">Data Analysis</button>
						<button class="skill">SQL</button>
						<button class="skill">NoSQL</button>
						<button class="skill">Data Analytics</button>
						<hr>

						<header class="major">
							<h4>Achievements:</h4>
						</header>
						&star; Ensured data accuracy compliance across Legacy and cloud systems, leveraging the PowerBI
						visualization tool to achieve a targeted accuracy level exceeding 90%.<br>
						&star; Reduced testing time up to 60% by developing automated test scenarios and applying oozie
						orchestration flows to execute in Amazon EMR cluster.<br>
						<hr>

						<header class="major">
							<h4>Responsibilities:</h4>
						</header>
						<ul>
							<li>Implemented Spark Scripting using Scala and Python to handle Big Data and complex data
								transformations.</li>
							<li>Worked on executing the Spark jobs in AWS Cloud environment with Oozie Orchestration
								flows.</li>
							<li>Attended Daily Scrum Meetings to provide continuous updates on the tasks assigned to
								Team Leads.</li>
							<li>Developed SQL scripts using Spark for handling different data sets.</li>
							<li>Interacted with the Business Analysis Team and Technical Support Team to cover the
								requirements and optimally design the data flow.</li>
							<li>Used various file formats such as text, JSON, CSV, and Parquet for input data
								requirements to Spark jobs.</li>
							<li>Had hands-on experience with Hadoop and associated technologies such as MapReduce,
								Spark, Pig, and Hive.</li>
							<li>Had domain knowledge in the Travel, Transport, and Hospitality Industry.</li>
						</ul>
					</div>

				</div>
			</section>


			<hr class="separation-line">


			<!-- Four -->
			<section id="mindtreeTE">
				<div class="inner">
					<header class="major">
						<h2>Mindtree</h2>
					</header>
					<div class="container">
						<div class="content">
							<p>Trainee - Software Engineer</p>
						</div>
						<div class="content" style="text-align: center;">
							<p>October 2018 - December 2018</p>
						</div>
						<hr>
						<header class="major">
							<h4>Responsibilities:</h4>
						</header>

						<ul>
							<li>Trained on wide range on technologies with specialization in Big Data.
							<li>Trained on Big Data technologies such as Hadoop usage (HDFS, YARN), Hive, HBase, Kafka,
								Spark etc.
							<li>Trained on AWS cloud services such as EC2, S3, EMR, RDS, SNS, Route53, Snowball, IAM,
								Glacier etc.
						</ul>
					</div>

				</div>
			</section>

			<hr class="separation-line">

			<button onclick="topFunction()" id="topButton" title="Go to top">TOP</button>


			<!-- Footer -->
			<footer id="footer">
				<div class="inner">
					<div class="center-icons">
						<ul class="icons">
							<li><a href="https://twitter.com/vijay_jawali" class="icon brands alt fa-twitter"
									target="_blank"><span class="label">Twitter</span></a></li>
							<li><a href="https://www.facebook.com/vijayjawali" class="icon brands alt fa-facebook-f"
									target="_blank"><span class="label">Facebook</span></a></li>
							<li><a href="https://www.instagram.com/vijayjawali/" class="icon brands alt fa-instagram"
									target="_blank"><span class="label">Instagram</span></a></li>
							<li><a href="https://github.com/vijayjawali" class="icon brands alt fa-github"
									target="_blank"><span class="label">GitHub</span></a></li>
							<li><a href="https://www.linkedin.com/in/vijayjawali/"
									class="icon brands alt fa-linkedin-in" target="_blank"><span
										class="label">LinkedIn</span></a></li>
						</ul>
					</div>
					<ul class="copyright">
						<li>&copy; Vijay Jawali</li>
						<li>Design: <a href="https://html5up.net">HTML5 UP</a></li>
					</ul>
				</div>
			</footer>


		</div>

		<!-- Scripts -->
		<script src="assets/js/jquery.min.js"></script>
		<script src="assets/js/jquery.scrolly.min.js"></script>
		<script src="assets/js/jquery.scrollex.min.js"></script>
		<script src="assets/js/browser.min.js"></script>
		<script src="assets/js/breakpoints.min.js"></script>
		<script src="assets/js/util.js"></script>
		<script src="assets/js/main.js"></script>
		<script>
			// When the user scrolls down 20px from the top of the document, show the button
			window.onscroll = function () { scrollFunction() };

			function scrollFunction() {
				if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
					document.getElementById("topButton").style.display = "block";
				} else {
					document.getElementById("topButton").style.display = "none";
				}
			}

			// When the user clicks on the button, scroll to the top of the document
			function topFunction() {
				document.body.scrollTop = 0;
				document.documentElement.scrollTop = 0;
			}
		</script>

</body>

</html>